{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahadfaruqi/Desktop/health-hopper/env/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # Load the feature extractor\n",
    "# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"../pre-trained-models/preprocessor_config.json\", local_files_only=True)\n",
    "# save_directory = \"./\"\n",
    "\n",
    "# # Save the model\n",
    "# feature_extractor.save_pretrained(save_directory)\n",
    "\n",
    "# Load the model\n",
    "# model = ViTForImageClassification.from_pretrained('steven123/Check_GoodBad_Teeth')\n",
    "# # 0: Bad, 1: Good\n",
    "# save_directory = \"./\"\n",
    "\n",
    "# # Save the model\n",
    "# model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "response = requests.get(r'https://www.fhdc.co.uk/wp-content/uploads/blog-images-2-4.jpg')\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Preprocess the image\n",
    "inputs = feature_extractor(images=img, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "outputs = model(**inputs)\n",
    "probabilities = outputs.logits.softmax(dim=-1)\n",
    "\n",
    "print(\"Predicted class:\", probabilities.argmax(-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
